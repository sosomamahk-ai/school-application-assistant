import { openai } from '@/lib/openai';
import type { FormField } from '@/types';

export interface GeneratedTemplate {
  schoolName: string;
  fields: FormField[];
}

/**
 * Generate template JSON from raw form content (HTML, text, etc.)
 * Uses LLM to analyze and extract form structure
 */
export async function generateTemplateFromFormContent(
  rawContent: string,
  sourceType: 'url' | 'pdf' | 'docx' = 'url'
): Promise<{ template: GeneratedTemplate; confidence: number; fieldCount: number }> {
  console.log(`[LLM Template] Starting template generation from ${sourceType}. Content length: ${rawContent.length} chars`);
  
  if (!rawContent || rawContent.trim().length === 0) {
    throw new Error('Raw content is empty. Cannot generate template from empty content.');
  }

  // Check if OpenAI is configured
  if (!openai) {
    console.error(`[LLM Template] OpenAI API key not configured`);
    throw new Error('OpenAI API key not configured. Please set OPENAI_API_KEY environment variable.');
  }

  // Truncate content if too long (LLM has token limits)
  const maxContentLength = 15000;
  const truncatedContent = rawContent.length > maxContentLength 
    ? rawContent.substring(0, maxContentLength) + '\n\n[... content truncated for brevity ...]'
    : rawContent;
  
  console.log(`[LLM Template] Using ${truncatedContent.length} chars for LLM prompt`);

  const systemPrompt = `You are an expert at analyzing school application forms and extracting structured field information.

Your task is to analyze the provided form content and generate a JSON template that matches this exact schema:

{
  "schoolName": "string (extracted from the form or inferred)",
  "fields": [
    {
      "id": "string (snake_case, unique identifier)",
      "label": "string (the field label as it appears)",
      "type": "text" | "number" | "date" | "select" | "checkbox" | "radio" | "file" | "textarea" | "email" | "tel",
      "required": boolean,
      "options": string[] (only if type is "select" or "radio"),
      "placeholder": "string (optional)",
      "helpText": "string (optional, any help text or description)",
      "maxLength": number (optional, for text/textarea fields)
    }
  ]
}

Field type mapping rules:
- text: Single-line text input
- number: Numeric input
- date: Date picker
- select: Dropdown with options
- checkbox: Checkbox input
- radio: Radio button group
- file: File upload input
- textarea: Multi-line text input
- email: Email input
- tel: Phone number input

Important:
1. Extract ALL form fields you can identify
2. Determine if fields are required (look for asterisks, "required" text, etc.)
3. For select/radio fields, extract all available options
4. Use descriptive, unique IDs in snake_case format
5. Preserve original labels exactly as they appear
6. Infer field types from context and labels
7. Extract any placeholder text or help text

Return ONLY valid JSON, no additional text or explanation.`;

  const userPrompt = `Analyze the following ${sourceType === 'url' ? 'HTML form' : sourceType === 'pdf' ? 'PDF document' : 'Word document'} content and extract all form fields:

${truncatedContent}

Generate the JSON template following the schema exactly. Be thorough and extract all fields you can identify.`;

  try {
    // Log request details
    const baseURL = process.env.OPENAI_BASE_URL || process.env.OPENAI_PROXY_URL || 'https://api.openai.com';
    const requestURL = baseURL ? `${baseURL}/v1/chat/completions` : 'https://api.openai.com/v1/chat/completions';
    
    console.log(`[LLM Template] Sending request to OpenAI (model: gpt-4o-mini)...`);
    console.log(`[LLM Template] Request URL: ${requestURL}`);
    console.log(`[LLM Template] Base URL: ${baseURL || 'default'}`);
    console.log(`[LLM Template] API Key: ${process.env.OPENAI_API_KEY ? process.env.OPENAI_API_KEY.substring(0, 10) + '...' : 'NOT SET'}`);
    
    const requestStartTime = Date.now();
    
    const completion = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt }
      ],
      temperature: 0,
      response_format: { type: 'json_object' }
    });

    const requestTime = Date.now() - requestStartTime;
    console.log(`[LLM Template] OpenAI request completed in ${requestTime}ms`);

    const responseContent = completion.choices[0]?.message?.content;
    if (!responseContent) {
      console.error(`[LLM Template] No response content from OpenAI`);
      throw new Error('No response from OpenAI. The API did not return any content.');
    }

    console.log(`[LLM Template] Received response. Length: ${responseContent.length} chars`);
    console.log(`[LLM Template] Response preview: ${responseContent.substring(0, 200)}...`);

    let parsed: any;
    try {
      parsed = JSON.parse(responseContent);
      console.log(`[LLM Template] Successfully parsed JSON response`);
    } catch (parseError) {
      console.error(`[LLM Template] Failed to parse JSON response: ${(parseError as Error).message}`);
      console.error(`[LLM Template] Response content: ${responseContent}`);
      throw new Error(`Failed to parse LLM response as JSON: ${(parseError as Error).message}`);
    }
    
    // Validate and normalize the response
    const template: GeneratedTemplate = {
      schoolName: parsed.schoolName || 'Unknown School',
      fields: Array.isArray(parsed.fields) ? parsed.fields.map((field: any, index: number) => ({
        id: field.id || `field_${Date.now()}_${index}`,
        label: field.label || 'Unnamed Field',
        type: field.type || 'text',
        required: Boolean(field.required),
        options: field.options || undefined,
        placeholder: field.placeholder || undefined,
        helpText: field.helpText || undefined,
        maxLength: field.maxLength || undefined
      })) : []
    };

    console.log(`[LLM Template] Generated template with ${template.fields.length} fields for school: ${template.schoolName}`);

    // Calculate confidence based on field count and completeness
    const fieldCount = template.fields.length;
    const hasRequiredInfo = template.schoolName !== 'Unknown School';
    const confidence = Math.min(0.95, 0.5 + (fieldCount * 0.05) + (hasRequiredInfo ? 0.2 : 0));

    console.log(`[LLM Template] Template generation completed. Confidence: ${confidence.toFixed(2)}, Fields: ${fieldCount}`);

    return {
      template,
      confidence,
      fieldCount
    };
  } catch (error) {
    console.error(`[LLM Template] Template generation error: ${(error as Error).message}`);
    console.error(`[LLM Template] Stack: ${(error as Error).stack}`);
    
    const errorStatus = (error as any).status || (error as any).response?.status;
    const errorCode = (error as any).code;
    const errorMessage = (error as Error).message;
    const baseURL = process.env.OPENAI_BASE_URL || process.env.OPENAI_PROXY_URL;
    
    // Log additional debug information
    console.error(`[LLM Template] Error details:`, {
      message: errorMessage,
      status: errorStatus,
      code: errorCode,
      baseURL: baseURL || 'not set (using default)',
      type: error?.constructor?.name || 'Unknown'
    });
    
    // Handle connection errors specifically
    if (errorMessage.includes('Connection error') || 
        errorMessage.includes('ECONNREFUSED') ||
        errorMessage.includes('ENOTFOUND') ||
        errorMessage.includes('ETIMEDOUT') ||
        errorMessage.includes('getaddrinfo') ||
        errorCode === 'ECONNREFUSED' ||
        errorCode === 'ENOTFOUND' ||
        errorCode === 'ETIMEDOUT') {
      
      // Check for underlying error cause
      const underlyingError = (error as any).error || (error as any).cause;
      const underlyingCode = underlyingError?.code || (error as any).errno;
      const underlyingMessage = underlyingError?.message || errorMessage;
      
      console.error(`[LLM Template] Connection error details:`, {
        message: errorMessage,
        code: errorCode,
        underlyingCode: underlyingCode,
        underlyingMessage: underlyingMessage,
        baseURL: baseURL,
        fullError: JSON.stringify(error, Object.getOwnPropertyNames(error), 2)
      });
      
      let connectionErrorMsg = 'æ— æ³•è¿æ¥åˆ° OpenAI APIã€‚';
      
      if (baseURL) {
        connectionErrorMsg += `\n\nä»£ç†é…ç½®ï¼š${baseURL}`;
        
        if (underlyingCode === 'ENOTFOUND' || underlyingMessage?.includes('getaddrinfo')) {
          connectionErrorMsg += `\n\nğŸ’¡ è¯Šæ–­ï¼šDNS è§£æå¤±è´¥ï¼ˆENOTFOUNDï¼‰`;
          connectionErrorMsg += `\n\nå¯èƒ½çš„åŸå› ï¼š`;
          connectionErrorMsg += `\n1. æœ¬åœ° DNS æœåŠ¡å™¨æ— æ³•è§£æ Worker åŸŸåï¼ˆä½†æµè§ˆå™¨å¯ä»¥è®¿é—®ï¼Œè¯´æ˜åŸŸåæ­£ç¡®ï¼‰`;
          connectionErrorMsg += `\n2. Node.js ç¯å¢ƒä¸‹çš„ç½‘ç»œé…ç½®é—®é¢˜`;
          connectionErrorMsg += `\n3. é˜²ç«å¢™æˆ–ä»£ç†è®¾ç½®é˜»æ­¢äº† Node.js çš„ç½‘ç»œè®¿é—®`;
          connectionErrorMsg += `\n\nâœ… Worker å·²éƒ¨ç½²æˆåŠŸï¼ˆæµè§ˆå™¨å¯ä»¥è®¿é—®ï¼‰`;
          connectionErrorMsg += `\nâœ… é…ç½®æ­£ç¡®ï¼ˆOPENAI_BASE_URL å·²è®¾ç½®ï¼‰`;
          connectionErrorMsg += `\n\nè§£å†³æ–¹æ¡ˆï¼š`;
          connectionErrorMsg += `\n1. è™½ç„¶æœ¬åœ°æµ‹è¯•å¤±è´¥ï¼Œä½†åº”ç”¨åœ¨ç”Ÿäº§ç¯å¢ƒä¸­å¯èƒ½ä»ç„¶å¯ç”¨`;
          connectionErrorMsg += `\n2. å°è¯•åˆ·æ–° DNS ç¼“å­˜ï¼šipconfig /flushdnsï¼ˆWindowsï¼‰`;
          connectionErrorMsg += `\n3. æ£€æŸ¥é˜²ç«å¢™æ˜¯å¦é˜»æ­¢äº† Node.js çš„ç½‘ç»œè®¿é—®`;
          connectionErrorMsg += `\n4. å¦‚æœåº”ç”¨ä»ç„¶æŠ¥é”™ï¼Œå¯èƒ½æ˜¯åº”ç”¨æœªé‡å¯ï¼ˆç¯å¢ƒå˜é‡æœªåŠ è½½ï¼‰`;
          connectionErrorMsg += `\n5. è¯·ç¡®ä¿åº”ç”¨å·²å®Œå…¨é‡å¯ä»¥åŠ è½½æ–°çš„ç¯å¢ƒå˜é‡`;
        } else {
          connectionErrorMsg += `\n\nå¯èƒ½çš„åŸå› ï¼š`;
          connectionErrorMsg += `\n1. ä»£ç†æœåŠ¡å™¨å¯èƒ½æ— æ³•è®¿é—®ï¼ˆæ£€æŸ¥ Cloudflare Workers æ˜¯å¦æ­£å¸¸è¿è¡Œï¼‰`;
          connectionErrorMsg += `\n2. ä»£ç† URL é…ç½®å¯èƒ½ä¸æ­£ç¡®ï¼ˆæ£€æŸ¥ OPENAI_BASE_URL æ˜¯å¦æ­£ç¡®ï¼‰`;
          connectionErrorMsg += `\n3. ç½‘ç»œè¿æ¥é—®é¢˜ï¼ˆæ£€æŸ¥ç½‘ç»œè¿æ¥ï¼‰`;
          connectionErrorMsg += `\n4. Cloudflare Workers ä»£ç å¯èƒ½æœ‰é—®é¢˜ï¼ˆæ£€æŸ¥ Worker ä»£ç ï¼‰`;
          connectionErrorMsg += `\n\nè¯·æ£€æŸ¥ï¼š`;
          connectionErrorMsg += `\n- åœ¨æµè§ˆå™¨ä¸­æµ‹è¯• Worker URLï¼š${baseURL}/v1/models`;
          connectionErrorMsg += `\n- æ£€æŸ¥ Cloudflare Workers æ—¥å¿—`;
          connectionErrorMsg += `\n- éªŒè¯ OPENAI_BASE_URL é…ç½®æ˜¯å¦æ­£ç¡®`;
        }
      } else {
        connectionErrorMsg += `\n\næœªé…ç½®ä»£ç†ã€‚å¦‚æœé‡åˆ°åœ°åŒºé™åˆ¶ï¼Œè¯·é…ç½® OPENAI_BASE_URL ç¯å¢ƒå˜é‡ã€‚`;
      }
      
      console.error(`[LLM Template] Connection error: ${connectionErrorMsg}`);
      throw new Error(connectionErrorMsg);
    }
    
    // Provide more specific error messages
    if (errorStatus === 403 || errorMessage.includes('Country, region, or territory not supported')) {
      const detailedMessage = 'OpenAI API is not available in your country/region. ' +
        'Solutions: 1) Use a VPN/proxy service, 2) Configure OpenAI API proxy in environment variables, ' +
        '3) Use Azure OpenAI Service (if available in your region), ' +
        '4) Contact your administrator for proxy configuration. ' +
        'For proxy setup, set OPENAI_BASE_URL environment variable (e.g., https://your-proxy.com/v1).';
      console.error(`[LLM Template] Region restriction error: ${detailedMessage}`);
      throw new Error(detailedMessage);
    }
    if (errorCode === 'insufficient_quota' || errorMessage.includes('insufficient_quota')) {
      throw new Error('OpenAI API quota exceeded. Please check your API key and billing at platform.openai.com/account/billing');
    }
    if (errorCode === 'invalid_api_key' || errorMessage.includes('Invalid API key') || errorStatus === 401) {
      throw new Error('Invalid OpenAI API key. Please check your OPENAI_API_KEY environment variable.');
    }
    if (errorStatus === 429 || errorMessage.includes('rate limit')) {
      throw new Error('OpenAI API rate limit exceeded. Please try again later or upgrade your plan.');
    }
    if (errorStatus === 500 || errorCode === 'internal_error') {
      throw new Error('OpenAI API internal error. Please try again later.');
    }
    
    // Generic error with more context
    throw new Error(`Failed to generate template: ${errorMessage}`);
  }
}

